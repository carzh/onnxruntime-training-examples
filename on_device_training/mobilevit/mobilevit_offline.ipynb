{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import onnx\n",
    "import numpy as np\n",
    "import onnxruntime.training.onnxblock as onnxblock\n",
    "from onnxruntime.training import artifacts\n",
    "from onnxruntime.training.onnxblock import blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = transformers.MobileViTFeatureExtractor.from_pretrained(\"apple/mobilevit-xx-small\")\n",
    "model = transformers.MobileViTForImageClassification.from_pretrained(\"apple/mobilevit-xx-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/nn/functional.py:2415: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if size_prods == 1:\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/transformers/models/mobilevit/modeling_mobilevit.py:452: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  new_height = int(math.ceil(orig_height / patch_height) * patch_height)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/transformers/models/mobilevit/modeling_mobilevit.py:453: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  new_width = int(math.ceil(orig_width / patch_width) * patch_width)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/transformers/models/mobilevit/modeling_mobilevit.py:456: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if new_width != orig_width or new_height != orig_height:\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.conv_stem.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.0.layer.0.expand_1x1.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.0.layer.0.conv_3x3.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.0.layer.0.reduce_1x1.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.1.layer.0.expand_1x1.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.1.layer.0.conv_3x3.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.1.layer.0.reduce_1x1.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.1.layer.1.expand_1x1.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.1.layer.1.conv_3x3.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.1.layer.1.reduce_1x1.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.1.layer.2.expand_1x1.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.1.layer.2.conv_3x3.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.1.layer.2.reduce_1x1.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.2.downsampling_layer.expand_1x1.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.2.downsampling_layer.conv_3x3.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.2.downsampling_layer.reduce_1x1.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.2.conv_kxk.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.2.conv_projection.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.2.fusion.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.3.downsampling_layer.expand_1x1.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.3.downsampling_layer.conv_3x3.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.3.downsampling_layer.reduce_1x1.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.3.conv_kxk.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.3.conv_projection.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.3.fusion.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.4.downsampling_layer.expand_1x1.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.4.downsampling_layer.conv_3x3.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.4.downsampling_layer.reduce_1x1.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.4.conv_kxk.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.4.conv_projection.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.encoder.layer.4.fusion.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
      "/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'mobilevit.conv_1x1_exp.normalization.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n",
      "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n"
     ]
    }
   ],
   "source": [
    "# model.classifier = torch.nn.Linear(320, 7)\n",
    "\n",
    "onnx_name = \"mobilevit_init_test.onnx\"\n",
    "\n",
    "# generates random pixel values for 5 images\n",
    "# originally images were 256 by 256\n",
    "# random_input = {\"pixel_values\": torch.rand(5, 3, 512, 512)}\n",
    "random_input = torch.rand(5, 3, 256, 256)\n",
    "\n",
    "torch.onnx.export(model, random_input, onnx_name,\n",
    "                    input_names=[\"input\"], output_names=[\"output\"],\n",
    "                    export_params=True,\n",
    "                    dynamic_axes={\n",
    "                        \"input\": {0: \"batch_size\"},\n",
    "                        \"output\": {0: \"batch_size\"}\n",
    "                    },\n",
    "                    do_constant_folding=False,\n",
    "                    training=torch.onnx.TrainingMode.TRAINING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "/bert_ort/carolinezhu/ort/onnxruntime/orttraining/orttraining/python/orttraining_pybind_state.cc:1068 onnxruntime::python::addObjectMethodsForTraining(pybind11::module&, onnxruntime::python::ExecutionProviderRegistrationFn)::<lambda(const pybind11::bytes&, const std::unordered_set<std::__cxx11::basic_string<char> >&)> [ONNXRuntimeError] : 1 : FAIL : Node (/mobilevit/encoder/layer.2/conv_projection/normalization/BatchNormalization_BatchNormInternal) Op (BatchNormInternal) [ShapeInferenceError] Dimension mismatch in unification between 48 and 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m     frozen_params\u001b[39m.\u001b[39mappend(name)\n\u001b[1;32m     12\u001b[0m onnx_model \u001b[39m=\u001b[39m onnx\u001b[39m.\u001b[39mload(onnx_name)\n\u001b[0;32m---> 14\u001b[0m artifacts\u001b[39m.\u001b[39;49mgenerate_artifacts(\n\u001b[1;32m     15\u001b[0m     onnx_model,\n\u001b[1;32m     16\u001b[0m     optimizer\u001b[39m=\u001b[39;49martifacts\u001b[39m.\u001b[39;49mOptimType\u001b[39m.\u001b[39;49mAdamW,\n\u001b[1;32m     17\u001b[0m     loss\u001b[39m=\u001b[39;49martifacts\u001b[39m.\u001b[39;49mLossType\u001b[39m.\u001b[39;49mCrossEntropyLoss,\n\u001b[1;32m     18\u001b[0m     requires_grad\u001b[39m=\u001b[39;49mrequires_grad,\n\u001b[1;32m     19\u001b[0m     frozen_params\u001b[39m=\u001b[39;49mfrozen_params\n\u001b[1;32m     20\u001b[0m )\n",
      "File \u001b[0;32m/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/onnxruntime/training/artifacts.py:124\u001b[0m, in \u001b[0;36mgenerate_artifacts\u001b[0;34m(model, requires_grad, frozen_params, loss, optimizer, artifact_directory, **extra_options)\u001b[0m\n\u001b[1;32m    122\u001b[0m model_params \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39mwith\u001b[39;00m onnxblock\u001b[39m.\u001b[39mbase(model):\n\u001b[0;32m--> 124\u001b[0m     _ \u001b[39m=\u001b[39m training_block(\u001b[39m*\u001b[39;49m[output\u001b[39m.\u001b[39;49mname \u001b[39mfor\u001b[39;49;00m output \u001b[39min\u001b[39;49;00m model\u001b[39m.\u001b[39;49mgraph\u001b[39m.\u001b[39;49moutput])\n\u001b[1;32m    125\u001b[0m     training_model, eval_model \u001b[39m=\u001b[39m training_block\u001b[39m.\u001b[39mto_model_proto()\n\u001b[1;32m    126\u001b[0m     model_params \u001b[39m=\u001b[39m training_block\u001b[39m.\u001b[39mparameters()\n",
      "File \u001b[0;32m/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/onnxruntime/training/onnxblock/onnxblock.py:200\u001b[0m, in \u001b[0;36mTrainingBlock.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parameters \u001b[39m=\u001b[39m _training_graph_utils\u001b[39m.\u001b[39mget_model_parameters(model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_requires_grad, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_frozen_params)\n\u001b[1;32m    194\u001b[0m \u001b[39m# Build the gradient graph. The gradient graph building is composed of the following steps:\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m#   - Move all model parameters to model inputs.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m#   - Run orttraining graph transformers on the model.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m#   - Add the gradient graph to the optimized model.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# The order of model inputs after gradient graph building is: user inputs, model parameters as inputs\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# The order of the model outputs is: user outputs, model parameter gradients (in the order of parameter inputs)\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_training_model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_model \u001b[39m=\u001b[39m _training_graph_utils\u001b[39m.\u001b[39;49mbuild_gradient_graph(\n\u001b[1;32m    201\u001b[0m     model,\n\u001b[1;32m    202\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_requires_grad,\n\u001b[1;32m    203\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_frozen_params,\n\u001b[1;32m    204\u001b[0m     output,\n\u001b[1;32m    205\u001b[0m )\n\u001b[1;32m    207\u001b[0m _training_graph_utils\u001b[39m.\u001b[39mbuild_gradient_accumulation_graph(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_training_model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_requires_grad)\n\u001b[1;32m    209\u001b[0m accessor\u001b[39m.\u001b[39m_GLOBAL_ACCESSOR\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mCopyFrom(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_training_model)\n",
      "File \u001b[0;32m/bert_ort/carolinezhu/e2edemos/lib/python3.9/site-packages/onnxruntime/training/onnxblock/_training_graph_utils.py:85\u001b[0m, in \u001b[0;36mbuild_gradient_graph\u001b[0;34m(model, requires_grad, frozen_params, output_names)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39m# At this point, eval model and training model diverge.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m eval_model \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(model)\n\u001b[0;32m---> 85\u001b[0m optimized_model \u001b[39m=\u001b[39m onnx\u001b[39m.\u001b[39mload_from_string(get_optimized_model(model\u001b[39m.\u001b[39;49mSerializeToString(), requires_grad))\n\u001b[1;32m     87\u001b[0m \u001b[39m# Assumption is that the first graph output is the loss output\u001b[39;00m\n\u001b[1;32m     88\u001b[0m gradient_model \u001b[39m=\u001b[39m _gradient_model_for(optimized_model, requires_grad, output_names, output_names[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mRuntimeError\u001b[0m: /bert_ort/carolinezhu/ort/onnxruntime/orttraining/orttraining/python/orttraining_pybind_state.cc:1068 onnxruntime::python::addObjectMethodsForTraining(pybind11::module&, onnxruntime::python::ExecutionProviderRegistrationFn)::<lambda(const pybind11::bytes&, const std::unordered_set<std::__cxx11::basic_string<char> >&)> [ONNXRuntimeError] : 1 : FAIL : Node (/mobilevit/encoder/layer.2/conv_projection/normalization/BatchNormalization_BatchNormInternal) Op (BatchNormInternal) [ShapeInferenceError] Dimension mismatch in unification between 48 and 1\n"
     ]
    }
   ],
   "source": [
    "requires_grad = []\n",
    "frozen_params = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        requires_grad.append(name)\n",
    "    else:\n",
    "        frozen_params.append(name)\n",
    "\n",
    "for name, param in model.named_buffers():\n",
    "    frozen_params.append(name)\n",
    "\n",
    "onnx_model = onnx.load(onnx_name)\n",
    "\n",
    "artifacts.generate_artifacts(\n",
    "    onnx_model,\n",
    "    optimizer=artifacts.OptimType.AdamW,\n",
    "    loss=artifacts.LossType.CrossEntropyLoss,\n",
    "    requires_grad=requires_grad,\n",
    "    frozen_params=frozen_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MobileViTFeatureExtractor, MobileViTForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "feature_extractor = MobileViTFeatureExtractor.from_pretrained(\"apple/mobilevit-xx-small\")\n",
    "model = MobileViTForImageClassification.from_pretrained(\"apple/mobilevit-xx-small\")\n",
    "\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "outputs.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inputs.pixel_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BatchFeature.keys of {'pixel_values': tensor([[[[0.2471, 0.2745, 0.3294,  ..., 0.1529, 0.1490, 0.1451],\n",
       "          [0.2510, 0.2471, 0.2745,  ..., 0.1529, 0.1373, 0.1412],\n",
       "          [0.2392, 0.2510, 0.2863,  ..., 0.1333, 0.1333, 0.1451],\n",
       "          ...,\n",
       "          [0.7098, 0.7255, 0.7176,  ..., 0.7412, 0.7137, 0.7216],\n",
       "          [0.7373, 0.7176, 0.7412,  ..., 0.7529, 0.7255, 0.7294],\n",
       "          [0.7373, 0.7451, 0.7373,  ..., 0.7137, 0.6824, 0.7294]],\n",
       "\n",
       "         [[0.1255, 0.1098, 0.1176,  ..., 0.0588, 0.0627, 0.0627],\n",
       "          [0.1216, 0.1216, 0.1373,  ..., 0.0588, 0.0627, 0.0471],\n",
       "          [0.1137, 0.1098, 0.1137,  ..., 0.0667, 0.0588, 0.0627],\n",
       "          ...,\n",
       "          [0.3216, 0.3098, 0.3373,  ..., 0.3373, 0.3569, 0.3255],\n",
       "          [0.3216, 0.3294, 0.3255,  ..., 0.3451, 0.3451, 0.3294],\n",
       "          [0.3216, 0.3569, 0.2980,  ..., 0.3490, 0.3529, 0.3176]],\n",
       "\n",
       "         [[0.5922, 0.5804, 0.6039,  ..., 0.4078, 0.4078, 0.3922],\n",
       "          [0.5804, 0.5686, 0.6039,  ..., 0.4078, 0.4118, 0.3922],\n",
       "          [0.5725, 0.5529, 0.5804,  ..., 0.3843, 0.4000, 0.4039],\n",
       "          ...,\n",
       "          [0.9294, 0.9255, 0.9373,  ..., 0.9490, 0.9490, 0.9333],\n",
       "          [0.9373, 0.9333, 0.9294,  ..., 0.9490, 0.9373, 0.9373],\n",
       "          [0.9294, 0.9529, 0.9059,  ..., 0.9451, 0.9373, 0.9333]]]])}>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = torch.nn.Linear(320, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
